{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63221437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca24767",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e28a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.6931\n",
      "Epoch 100, Cost: 0.6016\n",
      "Epoch 200, Cost: 0.5499\n",
      "Epoch 300, Cost: 0.5145\n",
      "Epoch 400, Cost: 0.4867\n",
      "Epoch 500, Cost: 0.4629\n",
      "Epoch 600, Cost: 0.4417\n",
      "Epoch 700, Cost: 0.4224\n",
      "Epoch 800, Cost: 0.4046\n",
      "Epoch 900, Cost: 0.3881\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "y = (y == 0).astype(int)  # Binary: Setosa vs Not Setosa\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# normalization\n",
    "def normalize(X):\n",
    "    minx = np.min(X, axis=0)\n",
    "    maxx = np.max(X, axis=0)\n",
    "    return (X - minx) / (maxx - minx)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# logistic regression\n",
    "def cost_func(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    cost = - (1 / m) * np.sum(\n",
    "        y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15)\n",
    "    )\n",
    "    return cost\n",
    "\n",
    "def logistic_regression(X, y, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Compute predictions\n",
    "        y_pred = sigmoid(np.dot(X, weights) + bias)\n",
    "        \n",
    "        # Compute gradients\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Update parameters\n",
    "        weights -= lr * dw\n",
    "        bias -= lr * db\n",
    "        \n",
    "\n",
    "        # Calculate cost to monitor learning progress\n",
    "        cost_history = []\n",
    "        cost = cost_func(y, y_pred)\n",
    "        cost_history.append(cost)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Cost: {cost:.4f}\")\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "\n",
    "# Prediction\n",
    "def predict(X, weights, bias):\n",
    "    return sigmoid(np.dot(X, weights) + bias)\n",
    "\n",
    "# Train and predict\n",
    "weights, bias = logistic_regression(X_train, y_train)\n",
    "y_pred_prob = predict(X_test, weights, bias)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a649f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': array([-0.5766677 ,  0.46959185, -1.01091752, -1.03441357]), 'bias': np.float64(0.06359140662395034), 'learning_rate': 0.1, 'epochs': 1000}\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"weights\": weights,\n",
    "    \"bias\": bias,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"epochs\": 1000\n",
    "}\n",
    "print(model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52a79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "TP: 8, FP: 0\n",
      "TN: 22, FN: 0\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))  # True Positive\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))  # False Positive\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))  # True Negative\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))  # False Negative\n",
    "\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "TP, FP, TN, FN = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"TP: {TP}, FP: {FP}\")\n",
    "print(f\"TN: {TN}, FN: {FN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d020c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "def sensitivity(TP, FN):\n",
    "    return TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "\n",
    "def specificity(TN, FP):\n",
    "    return TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "def precision(TP, FP):\n",
    "    return TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "\n",
    "def F_score(prec, recall):\n",
    "    return 2*(prec*recall)/(prec + recall) if prec + recall != 0 else 0\n",
    "\n",
    "recall = sensitivity(TP,FN)\n",
    "spec = specificity(TN,FP)\n",
    "prec = precision(TP,FP)\n",
    "Fscore = F_score(prec,recall)\n",
    "\n",
    "print(recall,spec,prec,Fscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "# Save weights and bias\n",
    "os.makedirs(\"model_artifacts\", exist_ok=True)\n",
    "with open(\"model_artifacts/weights.pkl\", \"wb\") as f:\n",
    "    pickle.dump(weights, f)\n",
    "with open(\"model_artifacts/bias.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bias, f)\n",
    "    \n",
    "class CustomLogisticRegression(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        self.weights = pickle.load(open(context.artifacts[\"weights\"], \"rb\"))\n",
    "        self.bias = pickle.load(open(context.artifacts[\"bias\"], \"rb\"))\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        return (1 / (1 + np.exp(-(model_input @ self.weights + self.bias))) >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa218800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 477.87it/s] \n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 251.34it/s]\n",
      "Registered model 'logistic regression' already exists. Creating a new version of this model...\n",
      "2025/04/12 18:27:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic regression, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run upset-stag-684 at: http://127.0.0.1:5000/#/experiments/384315332130507177/runs/41db3d9d02374d6697bdf5cfbe192aca\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/384315332130507177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'logistic regression'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Logistic Regression\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"weights\":weights,\n",
    "        \"Bias\":bias,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"epochs\": 1000,\n",
    "        \"model_type\": \"LogisticRegression\"\n",
    "    })\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy,\n",
    "        \"sensitivity\": recall,\n",
    "        \"specificity\": spec,\n",
    "        \"precision\":prec,\n",
    "        \"F-measure\": Fscore\n",
    "    })\n",
    "    \n",
    "    mlflow.log_artifact(\"model_artifacts/weights.pkl\", artifact_path=\"weights\")\n",
    "    mlflow.log_artifact(\"model_artifacts/bias.pkl\", artifact_path=\"bias\")\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"logreg_model\",\n",
    "        signature = infer_signature(X_train, y_pred),\n",
    "\n",
    "        python_model=CustomLogisticRegression(),\n",
    "        registered_model_name= \"logistic regression\",\n",
    "        artifacts={\n",
    "            \"weights\": \"model_artifacts/weights.pkl\",\n",
    "            \"bias\": \"model_artifacts/bias.pkl\"\n",
    "        }\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
